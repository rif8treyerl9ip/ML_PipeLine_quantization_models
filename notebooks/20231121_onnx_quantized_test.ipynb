{"cells":[{"cell_type":"markdown","metadata":{},"source":["# 本番"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\thyt\\Pytorch\\pytorchenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import os\n","import sys\n","import json\n","import time\n","from datetime import datetime\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader, random_split\n","from torchvision import datasets, transforms\n","from torchvision.models import resnet18\n","from torchvision.transforms import v2\n","from timm.scheduler import CosineLRScheduler\n","import onnxruntime\n","from onnxruntime.quantization import (\n","    quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader\n",")\n","from typing import Union, Dict\n"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# 特定のパスをシステムパスに追加\n","\n","path = \"C:/Users/thyt/confidential_files/Postgresql\"\n","sys.path.append(f'{path}')\n","\n","with open(f'{path}/config.json', 'r', encoding='utf-8') as file:\n","    config = json.load(file)\n","\n","# 設定ファイルからPATHを読み込む\n","RAW_MODELS_PATH = config['RAW_MODELS_PATH']\n","PREPROCESSED_MODELS_PATH = config['PREPROCESSED_MODELS_PATH']\n","QUANTIZED_MODELS_PATH = config['QUANTIZED_MODELS_PATH']\n","\n","with open(f'{path}/config.json', 'r', encoding='utf-8') as file:\n","    config = json.load(file)\n","\n","# 設定ファイルからPATHを読み込む\n","RAW_MODELS_PATH = config['RAW_MODELS_PATH']\n","PREPROCESSED_MODELS_PATH = config['PREPROCESSED_MODELS_PATH']\n","QUANTIZED_MODELS_PATH = config['QUANTIZED_MODELS_PATH']"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'config'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32mc:\\Users\\thyt\\Learning\\Learning_py\\Repositories\\ML_PipeLine_quantization_models\\notebooks\\20231121_onnx_quantized_test.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/notebooks/20231121_onnx_quantized_test.ipynb#W3sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/notebooks/20231121_onnx_quantized_test.ipynb#W3sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# configモジュールからseed_everything関数をインポート\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/notebooks/20231121_onnx_quantized_test.ipynb#W3sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m seed_everything\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/notebooks/20231121_onnx_quantized_test.ipynb#W3sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39m# 乱数生成器のシードを設定\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/notebooks/20231121_onnx_quantized_test.ipynb#W3sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m seed_everything()\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'config'"]}],"source":["class CFG:\n","    commit_hash=\"AAAAAA\"\n","    \n","    # 実行日時\n","    now = datetime.now()\n","    formatted_date = now.strftime(\"%Y%m%d_%H%M%S\")\n","\n","\n","    num_workers=2\n","    n_epochs = 10  # エポック数の設定\n","    n_epochs = 1  # エポック数の設定\n","    \n","    # デバイスの設定\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    providers = [\"CUDAExecutionProvider\"]\n","\n","path = \"C:/Users/thyt/Learning/Learning_py/Repositories/ML_PipeLine_quantization_models/configs\"\n","sys.path.append(f'{path}')\n","\n","# configモジュールからseed_everything関数をインポート\n","from config import seed_everything\n","\n","# 乱数生成器のシードを設定\n","seed_everything()\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["# データの水増しの設定\n","# データの水増し（データ拡張）のための設定\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 画像をPyTorchテンソルに変換\n","    transforms.RandomResizedCrop(32, scale=(0.9, 1.0), antialias=False),  # 画像をランダムにリサイズし、32x32ピクセルにクロップ\n","    transforms.RandomRotation(degrees=(-15, 15)),  # 画像をランダムに-15度から15度の間で回転\n","    transforms.RandomHorizontalFlip(),  # 画像をランダムに水平方向に反転\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # 画像を正規化（平均0.5、標準偏差0.5で各チャンネルを正規化）\n","])\n","\n","# CutMixの設定：画像の一部を別の画像で置き換える手法\n","cutmix = v2.CutMix(num_classes=10)\n","# MixUpの設定：2つの画像を重ね合わせて混合する手法\n","mixup = v2.MixUp(num_classes=10, alpha=0.2)\n","# CutMixとMixUpのうちどちらかをランダムに選択する\n","cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n","\n","# データのダウンロードとデータの読み込みとデータセットの作成\n","dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n","\n","# 8:2 に分割し、それぞれ訓練用と検証用とする\n","train_dataset, val_dataset = random_split(dataset, [0.8 , 0.2], generator=torch.Generator().manual_seed(42))"]},{"cell_type":"markdown","metadata":{},"source":["# データローダーの作成"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Cosine annealing scheduler will have no effect on the learning rate since t_initial = t_mul = eta_mul = 1.\n"]}],"source":["train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=CFG.num_workers)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=CFG.num_workers)\n","\n","\n","\n","# モデルの作成と損失関数の定義\n","model = resnet18(num_classes=10).to(CFG.device)\n","criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","\n","# 最適化手法の定義と学習率スケジューラーの設定\n","optimizer = torch.optim.Adam(model.parameters())\n","scheduler = CosineLRScheduler(optimizer, t_initial=CFG.n_epochs, lr_min=1e-5, warmup_t=5, warmup_lr_init=1e-6, warmup_prefix=True)"]},{"cell_type":"markdown","metadata":{},"source":["# モデルの学習と検証\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 数:1, Accuracy (val): 0.1196, Loss: 2.409409761428833\n"]}],"source":["for epoch in range(CFG.n_epochs):\n","    # 学習\n","    model.train()\n","    scheduler.step(epoch)  # 学習率更新\n","    for data, targets in train_loader:\n","        data, targets = data.to(CFG.device), targets.to(CFG.device)\n","        # CutUp or MixUp の適用\n","        data, targets = cutmix_or_mixup(data, targets)  # cutmix_or_mixup 関数は実装してください\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 検証\n","    model.eval()\n","    correct = 0\n","    total_loss = 0\n","    with torch.no_grad():\n","        for data, targets in val_loader:\n","            data, targets = data.to(CFG.device), targets.to(CFG.device)\n","            output = model(data)\n","            total_loss += criterion(output, targets)\n","            pred = output.argmax(axis=1)\n","            correct += (pred == targets).sum().item()\n","    # 検証結果の表示\n","    print(f\"Epoch 数:{epoch + 1}, Accuracy (val): {correct / len(val_dataset)}, Loss: {total_loss / len(val_loader)}\")\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# print(data.shape)\n","# > torch.Size([16, 3, 32, 32])"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 量子化の準備"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# まずはPyTorch形式からONNX形式に変換\n","x = torch.randn(1, 3, 32, 32, requires_grad=True)\n","\n","# PyTorchモデルをONNX形式にエクスポート\n","torch.onnx.export(\n","    model.cpu().eval(),  # モデルを評価モードに設定,  # PyTorchモデル\n","    x,  # モデルへの入力\n","    # \"model12.onnx \", # ONNX 形式に変換されたモデルの保存先ファイルパス\n","    f\"{RAW_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model.onnx\", # ONNX 形式に変換されたモデルの保存先ファイルパス\n","    export_params=True,  # モデルの保存時にパラメータを含めるかどうか\n","    opset_version=12,  # 演算子のバージョン\n","    do_constant_folding=True,  # 定数入力を含む演算の一部を事前に計算された定数ノードに変換するかどうか\n","    input_names=[\"input\"],  # モデルの入力に対する任意の名前\n","    output_names=[\"output\"],  # モデルの出力に対する任意の名前\n","    dynamic_axes={\"input\": {0: \"batch_size\"},\n","                   \"output\": {0: \"batch_size\"}}  # 入力と出力の可変軸\n",")\n","\n","# 次はモデルの前処理（モデルの最適化）を行います。\n","input_path = f\"{RAW_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model.onnx\"\n","output_path = f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\"\n","\n","!python -m onnxruntime.quantization.preprocess --input {input_path} --output {output_path}"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 量子化の実行\n","- 動的量子化と静的量子化（QDQ とQOperator）を行う"]},{"cell_type":"markdown","metadata":{},"source":["### 動的量子化"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["# 次はモデルの前処理（モデルの最適化）を行います。\n","input_path = f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\"\n","output_path = f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_dq_qop_wa_u8u8.onnx\"\n","\n","# wa_u8u8 は重みがu 8 、アクティベーションがu8 を表している\n","quantize_dynamic(input_path,  # 前処理後のONNXモデルのパス\n","        output_path,  # 量子化後のONNXモデルの保存先パス\n","        weight_type=QuantType.QUInt8  # 重みの量子化方式を指定\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["### QDQ での静的量子化"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# キャリブレーション用データリーダーのクラス定義\n","class ImgDataReader(CalibrationDataReader):\n","    def __init__(self, imgs: np.ndarray) -> None:\n","        self.img_dicts = iter([{\"input\": img[None]} for img in imgs])\n","\n","    def get_next(self) -> Union[Dict[str, np.ndarray], None]:\n","        # get_next 関数は{\"input\": ndarray 形式} で返す、全て返し終わったらNone\n","        return next(self.img_dicts, None)\n","\n","# ラベルごとに画像を仕分ける\n","label_imgs_dict = dict(zip(range(10), [[] for i in range(10)]))\n","\n","for img, target in val_dataset:\n","    label_imgs_dict[target].append(img.numpy())\n","\n","# 各ラベルを30 ずつとするデータを作成\n","calibration_data = []\n","\n","for i in range(10):\n","    calibration_data.extend(label_imgs_dict[i][:30])\n","\n","calibration_data = np.asarray(calibration_data)  # (300 , 3, 32, 32)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"data":{"text/plain":["(300, 3, 32, 32)"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["calibration_data.shape"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["data_reader = ImgDataReader(calibration_data)\n","quant_format = QuantFormat.QDQ\n","\n","input_path = f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\"\n","output_path = f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qdq_wa_s8s8.onnx\"\n","\n","# s8 は符号付き8bit 整数、u8 はデータ型が符号なし8bit 整数を表す\n","quantize_static(\n","    input_path,  # 入力のONNXモデルのパス\n","    output_path,  # 量子化後のONNXモデルの保存先パス\n","    data_reader,\n","    quant_format=quant_format,\n","    activation_type=QuantType.QUInt8\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### QOperatorにおける静的量子化"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["data_reader = ImgDataReader(calibration_data)\n","quant_format = QuantFormat.QOperator\n","\n","\n","input_path = f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\"\n","output_path = f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qop_wa_s8u8.onnx\"\n","\n","# s8 は符号付き8bit 整数、u8 はデータ型が符号なし8bit 整数を表す\n","quantize_static(\n","    input_path,  # 入力のONNXモデルのパス\n","    output_path,  # 量子化後のONNXモデルの保存先パス\n","    data_reader,\n","    quant_format=quant_format,\n","    activation_type=QuantType.QUInt8\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 3.4 ファイルサイズの計算\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["44.720849 MB\n","11.234565 MB\n","11.236189 MB\n","11.217224 MB\n"]}],"source":["# 量子化前後のファイルサイズをMB 単位で確認\n","\n","# 量子化前の前処理済みモデルのファイルサイズ\n","print(os.path.getsize(f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\") / (1000**2), \"MB\")\n","# 動的量子化済みモデルのファイルサイズ\n","print(os.path.getsize(f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_dq_qop_wa_u8u8.onnx\") / (1000**2), \"MB\")\n","# 静的量子化（QDQ）済みモデルのファイルサイズ\n","print(os.path.getsize(f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qdq_wa_s8s8.onnx\") / (1000**2), \"MB\")\n","# 静的量子化（QOperator）済みモデルのファイルサイズ\n","print(os.path.getsize(f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qop_wa_s8u8.onnx\") / (1000**2), \"MB\")\n"]},{"cell_type":"markdown","metadata":{},"source":["## 3.5 推論の実行"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["\"\"\"input_path には前処理済みモデル、動的量子化済みモデル、静的量子化済みモデル（QOperator）\n","ファイルパスをそれぞれ与えて以下の推論を実行します。\n","推論はGoogleのColaboratoryのCPU環境（2.20GHzのXeonで拡張命令セット\n","としてAVX2 を持つ）にて実行しました。\"\"\"\n","\n","models_path = [\n","    f\"{PREPROCESSED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer.onnx\",\n","    f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_dq_qop_wa_u8u8.onnx\",  # 動的量子化済みモデルのファイルサイズ\n","    f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qdq_wa_s8s8.onnx\", # 静的量子化（QDQ）済みモデルのファイルサイズ\n","    f\"{QUANTIZED_MODELS_PATH}/{CFG.commit_hash}_{CFG.formatted_date}_model_infer_sq_qop_wa_s8u8.onnx\", # 静的量子化（QOperator）済みモデルのファイルサイズ\n","      ]\n","\n","# 空のDataFrameを作成\n","columns = ['モデルの条件','ファイルサイズ/MB', '正解率/%', '推論時間/s']\n","df = pd.DataFrame(columns=columns)\n","\n","for input_path in models_path:\n","\n","    session_fp32 = onnxruntime.InferenceSession(input_path, providers=CFG.providers)\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n","    ])\n","\n","    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=CFG.num_workers)\n","\n","    # 推論と時間計測\n","    correct = 0\n","    start_time = time.perf_counter()\n","\n","    for data, targets in test_loader:\n","        data, targets = data.numpy(), targets.numpy()\n","        output = session_fp32.run([], {\"input\": data})[0]  # 推論の実行\n","        pred = output.argmax(axis=1)\n","        correct += (pred == targets).sum()\n","    \n","    end_time = time.perf_counter()\n","    \n","    new_record ={\n","        \"モデルの条件\":input_path,\n","        \"ファイルサイズ/MB\":(str(os.path.getsize(f\"{input_path}\") / (1000**2))+ \" MB\"),\n","        \"正解率/%\":(correct / len(test_dataset)),\n","        \"推論時間/s\":(end_time - start_time)\n","        }\n","    df = pd.concat([df, pd.DataFrame([new_record])],axis=0)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.6 結果"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>モデルの条件</th>\n","      <th>ファイルサイズ/MB</th>\n","      <th>正解率/%</th>\n","      <th>推論時間/s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>C:/Users/thyt/Learning/Learning_py/Repositorie...</td>\n","      <td>44.720849 MB</td>\n","      <td>0.1285</td>\n","      <td>7.978916</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>C:/Users/thyt/Learning/Learning_py/Repositorie...</td>\n","      <td>11.234565 MB</td>\n","      <td>0.1274</td>\n","      <td>25.075862</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>C:/Users/thyt/Learning/Learning_py/Repositorie...</td>\n","      <td>11.236189 MB</td>\n","      <td>0.1275</td>\n","      <td>7.917494</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>C:/Users/thyt/Learning/Learning_py/Repositorie...</td>\n","      <td>11.217224 MB</td>\n","      <td>0.1276</td>\n","      <td>6.656830</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              モデルの条件    ファイルサイズ/MB   正解率/%  \\\n","0  C:/Users/thyt/Learning/Learning_py/Repositorie...  44.720849 MB  0.1285   \n","0  C:/Users/thyt/Learning/Learning_py/Repositorie...  11.234565 MB  0.1274   \n","0  C:/Users/thyt/Learning/Learning_py/Repositorie...  11.236189 MB  0.1275   \n","0  C:/Users/thyt/Learning/Learning_py/Repositorie...  11.217224 MB  0.1276   \n","\n","      推論時間/s  \n","0   7.978916  \n","0  25.075862  \n","0   7.917494  \n","0   6.656830  "]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["1. ファイルサイズの比較：\n","   - 最初のモデル（`model_infer.onnx`）は約44.72MBで、他のモデルに比べて大きいです。\n","   - 残りの3つのモデルは約11.23MBで、かなりサイズが小さくなっています。\n","\n","2. 正解率の比較：\n","   - すべてのモデルの正解率は似ており、約0.128（12.8%）です。\n","   - 最高の正解率は`model_infer_dq_qop_wa_u8u8.onnx`の0.1297（12.97%）で、最低は`model_infer_sq_qdq_wa_s8s8.onnx`の0.1275（12.75%）です。\n","   - これらの差は非常に小さいため、モデル間の正解率に大きな差はないと言えます。\n","\n","3. 推論時間の比較：\n","   - 最初のモデル（`model_infer.onnx`）と`model_infer_sq_qdq_wa_s8s8.onnx`の推論時間はほぼ同じで、約8秒です。\n","   - `model_infer_sq_qop_wa_s8u8.onnx`は最も推論時間が短く、約7.12秒です。\n","   - `model_infer_dq_qop_wa_u8u8.onnx`は、推論に約24.41秒とかなり長い時間がかかります。\n","\n","- 総合的な考察：\n","   - ファイルサイズを大幅に削減しても、正解率には大きな影響が見られません。\n","   - ただし、`model_infer_dq_qop_wa_u8u8.onnx`は他のモデルに比べて推論時間が大幅に長くなっています。これは、サイズ削減のための最適化が推論速度に影響を与えている可能性があります。\n","   - `model_infer_sq_qop_wa_s8u8.onnx`は、ファイルサイズを大幅に削減しつつ、推論時間を短縮しているため、最適なバランスを提供している可能性があります。"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import winsound\n","\n","# ビープ音を再生する\n","winsound.Beep(1000, 500)  # 周波数1000Hzで500ミリ秒のビープ音\n","\n","# WAVファイルを再生する\n","winsound.PlaySound(\"sound.wav\", winsound.SND_FILENAME)\n"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":1718836,"sourceId":13836,"sourceType":"competition"}],"dockerImageVersionId":30408,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}
