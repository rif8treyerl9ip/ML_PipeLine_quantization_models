{"cells":[{"cell_type":"markdown","metadata":{},"source":["# import"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["c:\\Users\\thyt\\envs\\pytorchenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n","c:\\Users\\thyt\\envs\\pytorchenv\\lib\\site-packages\\pydantic\\_internal\\_config.py:321: UserWarning: Valid config keys have changed in V2:\n","* 'orm_mode' has been renamed to 'from_attributes'\n","  warnings.warn(message, UserWarning)\n","c:\\Users\\thyt\\envs\\pytorchenv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n","\n","You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n","  warnings.warn(\n","c:\\Users\\thyt\\envs\\pytorchenv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n","\n","You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n","  warnings.warn(\n","c:\\Users\\thyt\\envs\\pytorchenv\\lib\\site-packages\\pydantic\\_internal\\_fields.py:149: UserWarning: Field \"model_version_id\" has conflict with protected namespace \"model_\".\n","\n","You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n","  warnings.warn(\n"]}],"source":["import os\n","import sys\n","import json\n","import time\n","import uuid\n","from datetime import datetime\n","import subprocess\n","import numpy as np\n","import pandas as pd\n","from typing import Dict, List, Optional\n","import torch\n","from torch import nn\n","from torch.utils.data import DataLoader\n","from torchvision import datasets, transforms\n","from torchvision.models import resnet18\n","from torchvision.transforms import v2\n","from torch.utils.data import DataLoader, random_split\n","from timm.scheduler import CosineLRScheduler\n","import onnxruntime\n","from onnxruntime.quantization import (\n","   quantize_dynamic, quantize_static, QuantType, QuantFormat, CalibrationDataReader\n",")\n","from typing import Union\n","from sqlalchemy import create_engine, text\n","from sqlalchemy.orm import sessionmaker\n","from sqlalchemy import text\n","from sqlalchemy.orm import Session\n","\n","# パス設定\n","sys.path.append(\"../configs\")\n","sys.path.append('../db/')\n","\n","import config as cf\n","from config import seed_everything\n","\n","import src.db.models as models\n","import src.db.schemas as schemas\n","import src.db.cruds as cruds\n","\n","# パス読み込み\n","RAW_MODELS_PATH = cf.RAW_MODELS_PATH[0]\n","PREPROCESSED_MODELS_PATH = cf.PREPROCESSED_MODELS_PATH[0]\n","QUANTIZED_MODELS_PATH = cf.QUANTIZED_MODELS_PATH[0]\n","MODELS_DB_PATH= cf.MODELS_DB_PATH[0]\n","\n","# DB設定読み込み\n","with open('C:/Users/thyt/confidential_files/Postgresql/config.json', 'r', encoding='utf-8') as file:\n","    config = json.load(file)\n","\n","class DBConfigurations:\n","    postgres_username = config[\"POSTGRES_USER\"]\n","    postgres_password = config[\"POSTGRES_PASSWORD\"]\n","    postgres_port = int(config[\"POSTGRES_PORT\"])\n","    postgres_db = config[\"POSTGRES_DB\"]\n","    postgres_server = config[\"POSTGRES_SERVER\"]\n","    sql_alchemy_database_url = f\"postgresql://{postgres_username}:{postgres_password}@{postgres_server}:{postgres_port}/{postgres_db}\"\n","\n","engine = create_engine(DBConfigurations.sql_alchemy_database_url, pool_recycle=3600, echo=False)\n","SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\n","db = SessionLocal()\n"]},{"cell_type":"markdown","metadata":{},"source":["## CFG"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["class CFG:\n","    commit_hash=\"AAAAAA\"\n","    project_id=\"207503\"\n","\n","    now = datetime.now()\n","    formatted_date = now.strftime(\"%Y%m%d_%H%M%S\")\n","\n","    file_prefix = f\"{commit_hash}_{formatted_date}\"\n","    num_workers=2\n","    n_epochs = 1\n","    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","    providers = [\"CUDAExecutionProvider\"]\n","\n","seed_everything()"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n"]}],"source":["# データの水増しの設定\n","# データの水増し（データ拡張）のための設定\n","transform = transforms.Compose([\n","    transforms.ToTensor(),  # 画像をPyTorchテンソルに変換\n","    transforms.RandomResizedCrop(32, scale=(0.9, 1.0), antialias=False),  # 画像をランダムにリサイズし、32x32ピクセルにクロップ\n","    transforms.RandomRotation(degrees=(-15, 15)),  # 画像をランダムに-15度から15度の間で回転\n","    transforms.RandomHorizontalFlip(),  # 画像をランダムに水平方向に反転\n","    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),  # 画像を正規化（平均0.5、標準偏差0.5で各チャンネルを正規化）\n","])\n","\n","# CutMixの設定：画像の一部を別の画像で置き換える手法\n","cutmix = v2.CutMix(num_classes=10)\n","# MixUpの設定：2つの画像を重ね合わせて混合する手法\n","mixup = v2.MixUp(num_classes=10, alpha=0.2)\n","# CutMixとMixUpのうちどちらかをランダムに選択する\n","cutmix_or_mixup = v2.RandomChoice([cutmix, mixup])\n","\n","# データのダウンロードとデータの読み込みとデータセットの作成\n","dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\n","\n","# 8:2 に分割し、それぞれ訓練用と検証用とする\n","train_dataset, val_dataset = random_split(dataset, [0.8 , 0.2], generator=torch.Generator().manual_seed(42))"]},{"cell_type":"markdown","metadata":{},"source":["# データローダーの作成"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Cosine annealing scheduler will have no effect on the learning rate since t_initial = t_mul = eta_mul = 1.\n"]}],"source":["train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=CFG.num_workers)\n","val_loader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=CFG.num_workers)\n","\n","# モデルの作成と損失関数の定義\n","model = resnet18(num_classes=10).to(CFG.device)\n","criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","\n","# 最適化手法の定義と学習率スケジューラーの設定\n","optimizer = torch.optim.Adam(model.parameters())\n","scheduler = CosineLRScheduler(optimizer, t_initial=CFG.n_epochs, lr_min=1e-5, warmup_t=5, warmup_lr_init=1e-6, warmup_prefix=True)"]},{"cell_type":"markdown","metadata":{},"source":["# モデルの学習と検証\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 数:1, Accuracy (val): 0.1196, Loss: 2.409409761428833\n"]}],"source":["for epoch in range(CFG.n_epochs):\n","    # 学習\n","    model.train()\n","    scheduler.step(epoch)  # 学習率更新\n","    for data, targets in train_loader:\n","        data, targets = data.to(CFG.device), targets.to(CFG.device)\n","        # CutUp or MixUp の適用\n","        data, targets = cutmix_or_mixup(data, targets)  # cutmix_or_mixup 関数は実装してください\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","    # 検証\n","    model.eval()\n","    correct = 0\n","    total_loss = 0\n","    with torch.no_grad():\n","        for data, targets in val_loader:\n","            data, targets = data.to(CFG.device), targets.to(CFG.device)\n","            output = model(data)\n","            total_loss += criterion(output, targets)\n","            pred = output.argmax(axis=1)\n","            correct += (pred == targets).sum().item()\n","    # 検証結果の表示\n","    print(f\"Epoch 数:{epoch + 1}, Accuracy (val): {correct / len(val_dataset)}, Loss: {total_loss / len(val_loader)}\")\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# print(data.shape)\n","# > torch.Size([16, 3, 32, 32])"]},{"cell_type":"markdown","metadata":{},"source":["## 3.2 量子化の準備"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# まずはPyTorch形式からONNX形式に変換\n","x = torch.randn(1, 3, 32, 32, requires_grad=True)\n","\n","# PyTorchモデルをONNX形式にエクスポート\n","torch.onnx.export(\n","    model.cpu().eval(),  # モデルを評価モードに設定,  # PyTorchモデル\n","    x,  # モデルへの入力\n","    f\"{RAW_MODELS_PATH}/{CFG.file_prefix}_model.onnx\", # ONNX 形式に変換されたモデルの保存先ファイルパス\n","    export_params=True,  # モデルの保存時にパラメータを含めるかどうか\n","    opset_version=12,  # 演算子のバージョン\n","    do_constant_folding=True,  # 定数入力を含む演算の一部を事前に計算された定数ノードに変換するかどうか\n","    input_names=[\"input\"],  # モデルの入力に対する任意の名前\n","    output_names=[\"output\"],  # モデルの出力に対する任意の名前\n","    dynamic_axes={\"input\": {0: \"batch_size\"},\n","                   \"output\": {0: \"batch_size\"}}  # 入力と出力の可変軸\n",")\n","\n","# 次はモデルの前処理（モデルの最適化）を行います。\n","input_path = f\"{RAW_MODELS_PATH}/{CFG.file_prefix}_model.onnx\"\n","output_path = f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\"\n","\n","!python -m onnxruntime.quantization.preprocess --input {input_path} --output {output_path}"]},{"cell_type":"markdown","metadata":{},"source":["## 3.3 量子化の実行\n","- 動的量子化と静的量子化（QDQ とQOperator）を行う"]},{"cell_type":"markdown","metadata":{},"source":["### 動的量子化"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# 次はモデルの前処理（モデルの最適化）を行います。\n","\n","# wa_u8u8 は重みがu 8 、アクティベーションがu8 を表している\n","quantize_dynamic(f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\",  # 前処理後のONNXモデルのパス\n","        f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_dq_qop_wa_u8u8.onnx\",  # 量子化後のONNXモデルの保存先パス\n","        weight_type=QuantType.QUInt8  # 重みの量子化方式を指定\n","        )"]},{"cell_type":"markdown","metadata":{},"source":["### QDQ での静的量子化"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# キャリブレーション用データリーダーのクラス定義\n","class ImgDataReader(CalibrationDataReader):\n","    def __init__(self, imgs: np.ndarray) -> None:\n","        self.img_dicts = iter([{\"input\": img[None]} for img in imgs])\n","        [print(img[None]) for img in imgs]\n","\n","    def get_next(self) -> Union[Dict[str, np.ndarray], None]:\n","        # get_next 関数は{\"input\": ndarray 形式} で返す、全て返し終わったらNone\n","        return next(self.img_dicts, None)\n","\n","# ラベルごとに画像を仕分ける\n","label_imgs_dict = dict(zip(range(10), [[] for i in range(10)]))\n","\n","for img, target in val_dataset:\n","    label_imgs_dict[target].append(img.numpy())\n","\n","# 各ラベルを30 ずつとするデータを作成\n","calibration_data = []\n","\n","for i in range(10):\n","    calibration_data.extend(label_imgs_dict[i][:30])\n","\n","calibration_data = np.asarray(calibration_data)  # (300 , 3, 32, 32)"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":[" for img in imgsで書く画像を取り出す\n","画像のshapeは(3, 32, 32)\n","img[None]で(1, 3, 32, 32)に\n","\n","# キャリブレーション用データリーダーのクラス定義\n","class ImgDataReader(CalibrationDataReader):\n","    def __init__(self, imgs: np.ndarray) -> None:\n","        self.img_dicts = iter([{\"input\": img[None]} for img in imgs])\n","        # [print(img[None].shape) for img in imgs]\n","        [print(img.shape) for img in imgs]\n","\n","    def get_next(self) -> Union[Dict[str, np.ndarray], None]:\n","        # get_next 関数は{\"input\": ndarray 形式} で返す、全て返し終わったらNone\n","        return next(self.img_dicts, None)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n","(3, 32, 32)\n"]},{"data":{"text/plain":["<__main__.ImgDataReader at 0x1fb25d20f40>"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["ImgDataReader(calibration_data)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["data_reader = ImgDataReader(calibration_data)\n","quant_format = QuantFormat.QDQ\n","\n","# s8 は符号付き8bit 整数、u8 はデータ型が符号なし8bit 整数を表す\n","quantize_static(\n","    f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\",  # 入力のONNXモデルのパス\n","    f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qdq_wa_s8s8.onnx\",  # 量子化後のONNXモデルの保存先パス\n","    data_reader,\n","    quant_format=quant_format,\n","    activation_type=QuantType.QUInt8\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### QOperatorにおける静的量子化"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["data_reader = ImgDataReader(calibration_data)\n","quant_format = QuantFormat.QOperator\n","\n","# s8 は符号付き8bit 整数、u8 はデータ型が符号なし8bit 整数を表す\n","quantize_static(\n","    f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\",  # 入力のONNXモデルのパス\n","    f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qop_wa_s8u8.onnx\",  # 量子化後のONNXモデルの保存先パス\n","    data_reader,\n","    quant_format=quant_format,\n","    activation_type=QuantType.QUInt8\n",")"]},{"cell_type":"markdown","metadata":{},"source":["### モデルの保存"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["model = cruds.add_model(\n","    db=db, project_id=CFG.project_id,\n","    model_name=f\"{CFG.file_prefix}_model.onnx\",\n","    description=\"RAWモデル\",\n","    commit = True,\n","    parent_model_id = None\n","    )\n","parent_model_id = model.model_id\n","\n","model_infer = cruds.add_model(\n","    db=db, project_id=CFG.project_id,\n","    model_name=f\"{CFG.file_prefix}_model_infer.onnx\",\n","    description=\"前処理済みのモデル\",\n","    commit = True,\n","    parent_model_id = parent_model_id\n","    )\n","\n","model_infer_dq_qop_wa_u8u8 = cruds.add_model(\n","    db=db, project_id=CFG.project_id,\n","    model_name=f\"{CFG.file_prefix}_model_infer_dq_qop_wa_u8u8.onnx\",\n","    description=\"動的量子化済みモデル\",\n","    commit = True,\n","    parent_model_id = parent_model_id\n","    )\n","\n","model_infer_sq_qdq_wa_s8s8 = cruds.add_model(\n","    db=db, project_id=CFG.project_id,\n","    model_name=f\"{CFG.file_prefix}_model_infer_sq_qdq_wa_s8s8.onnx\",\n","    description=\"静的量子化（QDQ）済みモデル\",\n","    commit = True,\n","    parent_model_id = parent_model_id\n","    )\n","\n","model_infer_sq_qop_wa_s8u8 = cruds.add_model(\n","    db=db, project_id=CFG.project_id,\n","    model_name=f\"{CFG.file_prefix}_model_infer_sq_qop_wa_s8u8.onnx\",\n","    description=\"静的量子化（QOperator）済みモデル\",\n","    commit = True,\n","    parent_model_id = parent_model_id\n","    )\n","\n","model_id_model_infer = model_infer.model_id\n","model_id_model_infer_dq_qop_wa_u8u8 = model_infer_dq_qop_wa_u8u8.model_id\n","model_id_model_infer_sq_qdq_wa_s8s8 = model_infer_sq_qdq_wa_s8s8.model_id\n","model_id_model_infer_sq_qop_wa_s8u8 = model_infer_sq_qop_wa_s8u8.model_id\n","\n","experiment_args = [\n","    {\n","        \"model_path\": f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\",\n","        \"model_version_id\":\"v0.1\",\n","        \"model_id\":model_id_model_infer,\n","        \"parameters\":None,\n","        \"training_dataset_path\":\"\",\n","        \"validation_dataset_path\":\"\",\n","        \"test_dataset_path\":\"\",\n","        \"artifact_file_paths\":[f\"{PREPROCESSED_MODELS_PATH}/{CFG.file_prefix}_model_infer.onnx\"],\n","        \"commit\":True\n","    },\n","    {\n","        \"model_path\": f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_dq_qop_wa_u8u8.onnx\",  # 動的量子化済みモデルのファイルサイズ\n","        \"model_version_id\":\"v0.1\",\n","        \"model_id\":model_id_model_infer_dq_qop_wa_u8u8,\n","        \"parameters\":None,\n","        \"training_dataset_path\":\"\",\n","        \"validation_dataset_path\":\"\",\n","        \"test_dataset_path\":\"\",\n","        \"artifact_file_paths\":[f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_dq_qop_wa_u8u8.onnx\"],\n","        \"commit\":True\n","    },\n","    {\n","        \"model_path\": f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qdq_wa_s8s8.onnx\", # 静的量子化（QDQ）済みモデルのファイルサイズ\n","        \"model_version_id\":\"v0.1\",\n","        \"model_id\":model_id_model_infer_sq_qdq_wa_s8s8,\n","        \"parameters\":None,\n","        \"training_dataset_path\":\"\",\n","        \"validation_dataset_path\":\"\",\n","        \"test_dataset_path\":\"\",\n","        \"artifact_file_paths\":[f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qdq_wa_s8s8.onnx\"],\n","        \"commit\":True\n","    },\n","    {\n","        \"model_path\": f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qop_wa_s8u8.onnx\", # 静的量子化（QOperator）済みモデルのファイルサイズ\n","        \"model_version_id\":\"v0.1\",\n","        \"model_id\":model_id_model_infer_sq_qop_wa_s8u8,\n","        \"parameters\":None,\n","        \"training_dataset_path\":\"\",\n","        \"validation_dataset_path\":\"\",\n","        \"test_dataset_path\":\"\",\n","        \"artifact_file_paths\":[f\"{QUANTIZED_MODELS_PATH}/{CFG.file_prefix}_model_infer_sq_qop_wa_s8u8.onnx\"],\n","        \"commit\":True\n","    }\n","]"]},{"cell_type":"markdown","metadata":{},"source":["## 3.5 推論の実行"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n","Files already downloaded and verified\n"]}],"source":["\"\"\"input_path には前処理済みモデル、動的量子化済みモデル、静的量子化済みモデル（QOperator）\n","ファイルパスをそれぞれ与えて以下の推論を実行します。\n","推論はGoogleのColaboratoryのCPU環境（2.20GHzのXeonで拡張命令セット\n","としてAVX2 を持つ）にて実行しました。\"\"\"\n","experiment_id_list = []\n","\n","for experiment in experiment_args:\n","    input_path = experiment['model_path']\n","\n","    session_fp32 = onnxruntime.InferenceSession(input_path, providers=CFG.providers)\n","\n","    transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]),\n","    ])\n","\n","    test_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n","    test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=CFG.num_workers)\n","\n","    # 推論と時間計測\n","    correct = 0\n","    start_time = time.perf_counter()\n","\n","    for data, targets in test_loader:\n","        data, targets = data.numpy(), targets.numpy()\n","        output = session_fp32.run([], {\"input\": data})[0]  # 推論の実行\n","        pred = output.argmax(axis=1)\n","        correct += (pred == targets).sum()\n","\n","    end_time = time.perf_counter()\n","\n","    evaluations ={\n","        \"モデルの条件\": input_path.split('/')[-1],\n","        \"ファイルサイズ/MB\":(str(os.path.getsize(f\"{input_path}\") / (1000**2))+ \" MB\"),  ## 3.4 ファイルサイズの計算\n","        \"正解率/%\":(correct / len(test_dataset)),\n","        \"推論時間/s\":(end_time - start_time)\n","        }\n","\n","    result = cruds.add_experiment(\n","        db=db,\n","        model_version_id=experiment[\"model_version_id\"],\n","        model_id=experiment[\"model_id\"],\n","        parameters=experiment[\"parameters\"],\n","        training_dataset_path=experiment[\"training_dataset_path\"],\n","        validation_dataset_path=experiment[\"validation_dataset_path\"],\n","        test_dataset_path=experiment[\"test_dataset_path\"],\n","        evaluations=evaluations,  # 評価は元のコードから取得\n","        artifact_file_paths=experiment[\"artifact_file_paths\"],\n","        commit=experiment[\"commit\"]\n","    )\n","    experiment_id_list.append(result.experiment_id)"]},{"cell_type":"markdown","metadata":{},"source":["## 3.6 精度・推論速度の可視化"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>モデルの条件</th>\n","      <th>ファイルサイズ/MB</th>\n","      <th>正解率/%</th>\n","      <th>推論時間/s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_180833_model_infer.onnx</td>\n","      <td>44.720849 MB</td>\n","      <td>0.1285</td>\n","      <td>7.607179</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>AAAAAA_20231125_180833_model_infer_dq_qop_wa_u...</td>\n","      <td>11.234565 MB</td>\n","      <td>0.1274</td>\n","      <td>26.624171</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>AAAAAA_20231125_180833_model_infer_sq_qdq_wa_s...</td>\n","      <td>11.236189 MB</td>\n","      <td>0.1280</td>\n","      <td>7.853049</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>AAAAAA_20231125_180833_model_infer_sq_qop_wa_s...</td>\n","      <td>11.217224 MB</td>\n","      <td>0.1290</td>\n","      <td>7.213629</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              モデルの条件    ファイルサイズ/MB   正解率/%  \\\n","0            AAAAAA_20231125_180833_model_infer.onnx  44.720849 MB  0.1285   \n","1  AAAAAA_20231125_180833_model_infer_dq_qop_wa_u...  11.234565 MB  0.1274   \n","2  AAAAAA_20231125_180833_model_infer_sq_qdq_wa_s...  11.236189 MB  0.1280   \n","3  AAAAAA_20231125_180833_model_infer_sq_qop_wa_s...  11.217224 MB  0.1290   \n","\n","      推論時間/s  \n","0   7.607179  \n","1  26.624171  \n","2   7.853049  \n","3   7.213629  "]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# 空のリストを初期化\n","tmp = []\n","\n","# experiment_id_listの各experiment_idに対して以下の処理を実行\n","for experiment_id in experiment_id_list:\n","    # model_idを取得（ここは使われていないようです）\n","    model_id = experiment[\"model_id\"],\n","\n","    # experiment_idに基づいて実験の詳細を取得し、tmpリストに追加\n","    tmp.append(\n","        [cruds.select_experiment_by_id(db, experiment_id).experiment_id,\n","         cruds.select_experiment_by_id(db, experiment_id).model_id,\n","         cruds.select_experiment_by_id(db, experiment_id).model_version_id,\n","         cruds.select_experiment_by_id(db, experiment_id).parameters,\n","         cruds.select_experiment_by_id(db, experiment_id).training_dataset_path,\n","         cruds.select_experiment_by_id(db, experiment_id).validation_dataset_path,\n","         cruds.select_experiment_by_id(db, experiment_id).test_dataset_path,\n","         cruds.select_experiment_by_id(db, experiment_id).evaluations,\n","         cruds.select_experiment_by_id(db, experiment_id).artifact_file_paths,\n","         cruds.select_experiment_by_id(db, experiment_id).created_datetime]\n","    )\n","\n","# tmpを使用してデータフレームを作成し、列名を設定\n","experiment_results = pd.DataFrame(tmp, columns=[\"experiment_id\", \"model_id\", \"model_version_id\", \"parameters\",\n","                                                \"training_dataset_path\", \"validation_dataset_path\",\n","                                                \"test_dataset_path\", \"evaluations\", \"artifact_file_paths\",\n","                                                \"created_datetime\"])\n","\n","# experiment_resultsデータフレームを表示\n","experiment_results\n","\n","# 評価結果を格納するための空のリストを初期化\n","data_list = []\n","\n","# experiment_resultsの各行に対して以下の処理を実行\n","for _, row in experiment_results.iterrows():\n","    # 評価結果をdata_dictに格納\n","    data_dict = row['evaluations']\n","\n","    # data_listにdata_dictを追加\n","    data_list.append(data_dict)\n","\n","# data_listを使用して評価結果のデータフレームを作成\n","pd.DataFrame(data_list)\n"]},{"cell_type":"markdown","metadata":{},"source":["1. ファイルサイズの比較：\n","   - 最初のモデル（`model_infer.onnx`）は約44.72MBで、他のモデルに比べて大きいです。\n","   - 残りの3つのモデルは約11.23MBで、かなりサイズが小さくなっています。\n","\n","2. 正解率の比較：\n","   - すべてのモデルの正解率は似ており、約0.128（12.8%）です。\n","   - 最高の正解率は`model_infer_dq_qop_wa_u8u8.onnx`の0.1297（12.97%）で、最低は`model_infer_sq_qdq_wa_s8s8.onnx`の0.1275（12.75%）です。\n","   - これらの差は非常に小さいため、モデル間の正解率に大きな差はないと言えます。\n","\n","3. 推論時間の比較：\n","   - 最初のモデル（`model_infer.onnx`）と`model_infer_sq_qdq_wa_s8s8.onnx`の推論時間はほぼ同じで、約8秒です。\n","   - `model_infer_sq_qop_wa_s8u8.onnx`は最も推論時間が短く、約7.12秒です。\n","   - `model_infer_dq_qop_wa_u8u8.onnx`は、推論に約24.41秒とかなり長い時間がかかります。\n","\n","- 総合的な考察：\n","   - ファイルサイズを大幅に削減しても、正解率には大きな影響が見られません。\n","   - ただし、`model_infer_dq_qop_wa_u8u8.onnx`は他のモデルに比べて推論時間が大幅に長くなっています。これは、サイズ削減のための最適化が推論速度に影響を与えている可能性があります。\n","   - `model_infer_sq_qop_wa_s8u8.onnx`は、ファイルサイズを大幅に削減しつつ、推論時間を短縮しているため、最適なバランスを提供している可能性があります。"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["import winsound\n","\n","# ビープ音を再生する\n","winsound.Beep(1000, 500)  # 周波数1000Hzで500ミリ秒のビープ音\n","\n","# WAVファイルを再生する\n","winsound.PlaySound(\"sound.wav\", winsound.SND_FILENAME)\n"]},{"cell_type":"markdown","metadata":{},"source":["## DB操作"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>モデルの条件</th>\n","      <th>ファイルサイズ/MB</th>\n","      <th>正解率/%</th>\n","      <th>推論時間/s</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_011819_model_infer.onnx</td>\n","      <td>44.720849 MB</td>\n","      <td>0.8137</td>\n","      <td>7.883786</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_011819_model_infer_dq_qop_wa_u...</td>\n","      <td>11.234564 MB</td>\n","      <td>0.8131</td>\n","      <td>24.908645</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_011819_model_infer_sq_qdq_wa_s...</td>\n","      <td>11.236187 MB</td>\n","      <td>0.8133</td>\n","      <td>7.425493</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_011819_model_infer_sq_qop_wa_s...</td>\n","      <td>11.217222 MB</td>\n","      <td>0.8132</td>\n","      <td>6.841749</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_180833_model_infer.onnx</td>\n","      <td>44.720849 MB</td>\n","      <td>0.1285</td>\n","      <td>7.607179</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_180833_model_infer_dq_qop_wa_u...</td>\n","      <td>11.234565 MB</td>\n","      <td>0.1274</td>\n","      <td>26.624171</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_180833_model_infer_sq_qdq_wa_s...</td>\n","      <td>11.236189 MB</td>\n","      <td>0.1280</td>\n","      <td>7.853049</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>AAAAAA_20231125_180833_model_infer_sq_qop_wa_s...</td>\n","      <td>11.217224 MB</td>\n","      <td>0.1290</td>\n","      <td>7.213629</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                              モデルの条件    ファイルサイズ/MB   正解率/%  \\\n","0                                                NaN           NaN     NaN   \n","0            AAAAAA_20231125_011819_model_infer.onnx  44.720849 MB  0.8137   \n","0  AAAAAA_20231125_011819_model_infer_dq_qop_wa_u...  11.234564 MB  0.8131   \n","0  AAAAAA_20231125_011819_model_infer_sq_qdq_wa_s...  11.236187 MB  0.8133   \n","0  AAAAAA_20231125_011819_model_infer_sq_qop_wa_s...  11.217222 MB  0.8132   \n","0                                                NaN           NaN     NaN   \n","0            AAAAAA_20231125_180833_model_infer.onnx  44.720849 MB  0.1285   \n","0  AAAAAA_20231125_180833_model_infer_dq_qop_wa_u...  11.234565 MB  0.1274   \n","0  AAAAAA_20231125_180833_model_infer_sq_qdq_wa_s...  11.236189 MB  0.1280   \n","0  AAAAAA_20231125_180833_model_infer_sq_qop_wa_s...  11.217224 MB  0.1290   \n","\n","      推論時間/s  \n","0        NaN  \n","0   7.883786  \n","0  24.908645  \n","0   7.425493  \n","0   6.841749  \n","0        NaN  \n","0   7.607179  \n","0  26.624171  \n","0   7.853049  \n","0   7.213629  "]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["sql_query = text(\"SELECT * FROM projects\")\n","results = db.execute(sql_query)\n","data = [result for result in results]\n","df_projects = pd.DataFrame(data)\n","\n","sql_query = text(\"SELECT * FROM models\")\n","results = db.execute(sql_query)\n","data = [result for result in results]\n","df_models = pd.DataFrame(data)\n","\n","sql_query = text(\"SELECT * FROM experiments\")\n","results = db.execute(sql_query)\n","data = [result for result in results]\n","df_experiments = pd.DataFrame(data)\n","\n","# df_projectsとdf_modelsをproject_idでleft join\n","df_joined = pd.merge(df_projects, df_models, on=\"project_id\", how=\"left\")\n","\n","# 結合後のデータフレームdf_joinedとdf_experimentsをmodel_idでleft join\n","final_df = pd.merge(df_joined, df_experiments, on=\"model_id\", how=\"left\")\n","\n","tmpdf = pd.DataFrame()\n","# evaluations列をイテレーション\n","for index, row in final_df.iterrows():\n","    tmpdf = pd.concat([tmpdf,pd.DataFrame([row['evaluations']])],axis=0)\n","\n","tmpdf = tmpdf.drop(columns=[0])\n","tmpdf"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":1718836,"sourceId":13836,"sourceType":"competition"}],"dockerImageVersionId":30408,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.0"}},"nbformat":4,"nbformat_minor":4}
